{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-dataName'], dest='dataName', nargs=None, const=None, default='miRNA-disease', type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-dataName', action='store', dest='dataName', default='miRNA-disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-negNum'], dest='negNum', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-negNum', action='store', dest='negNum', default=1, type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-userLayer'], dest='userLayer', nargs=None, const=None, default=[32, 16], type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-userLayer', action='store', dest='userLayer', default=[32,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-itemLayer'], dest='itemLayer', nargs=None, const=None, default=[32, 16], type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-itemLayer', action='store', dest='itemLayer', default=[32,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-userFLayer'], dest='userFLayer', nargs=None, const=None, default=[32, 16], type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-userFLayer', action='store', dest='userFLayer', default=[32,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-reg'], dest='reg', nargs=None, const=None, default=0.5, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parser.add_argument('-itemFLayer', action='store', dest='itemFLayer', default=[128, 32])\n",
    "parser.add_argument('-reg', action='store', dest='reg', default=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-alfha'], dest='alfha', nargs=None, const=None, default=0.7, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-alfha', action='store',dest='alfha',default = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-lr'], dest='lr', nargs=None, const=None, default=1e-05, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-lr', action='store', dest='lr', default=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-maxEpochs'], dest='maxEpochs', nargs=None, const=None, default=400, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-maxEpochs', action='store', dest='maxEpochs', default=400, type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-batchSize'], dest='batchSize', nargs=None, const=None, default=5000, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-batchSize', action='store', dest='batchSize', default=5000, type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-earlyStop'], dest='earlyStop', nargs=None, const=None, default=20, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-earlyStop', action='store', dest='earlyStop', default=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-topK'], dest='topK', nargs=None, const=None, default=10, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parser.add_argument('-checkPoint', action='store', dest='checkPoint', default='./checkPoint/')\n",
    "parser.add_argument('-topK', action='store', dest='topK', default=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-cvfold'], dest='cvfold', nargs=None, const=None, default=2, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-cvfold', action='store', dest='cvfold', default=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(alfha=0.7, batchSize=5000, cvfold=2, dataName='miRNA-disease', earlyStop=20, f='/root/.local/share/jupyter/runtime/kernel-f6d0adb4-9435-4d66-9dd2-bffb57873709.json', itemLayer=[32, 16], lr=1e-05, maxEpochs=400, negNum=1, reg=0.5, topK=10, userFLayer=[32, 16], userLayer=[32, 16])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate 5-fold training list\n",
    "# the total number of miRNA-disease associations\n",
    "training_samples_num = 11252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fold_num = args.cvfold\n",
    "# convert the number to a list\n",
    "l = np.arange(training_samples_num)\n",
    "# shuffle the list\n",
    "np.random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, fileName, Testinglist):\n",
    "        self.data, self.shape = self.getData(fileName)\n",
    "        self.userdata, self.UF_len = self.getFeatureData()\n",
    "        self.train, self.test = self.getTrainTest(Testinglist)\n",
    "        self.trainDict = self.getTrainDict()\n",
    "        self.testDict = self.getTestDict()\n",
    "\n",
    "    def getData(self, fileName):\n",
    "        if fileName == 'miRNA-disease':\n",
    "            print(\"Loading lncRNA-miRNA data set...\")\n",
    "            data = []\n",
    "            filePath = '../data/MVMTMDA/miRNA-disease_id.txt'\n",
    "#             filePath = './Data/ml-1m/ratings.dat'\n",
    "            u = 0\n",
    "            i = 0\n",
    "            maxr = 0.0\n",
    "            with open(filePath, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line:\n",
    "                        lines = line[:-1].split(\"::\")\n",
    "                        user = int(lines[0])\n",
    "                        movie = int(lines[1])\n",
    "                        score = float(lines[2])\n",
    "                        data.append((user, movie, score))\n",
    "                        if user > u:\n",
    "                            u = user\n",
    "                        if movie > i:\n",
    "                            i = movie\n",
    "                        if score > maxr:\n",
    "                            maxr = score\n",
    "            self.maxRate = maxr\n",
    "            print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\".format(u, i, len(data)))\n",
    "            return data, [u, i]\n",
    "        else:\n",
    "            print(\"Current data set is not support!\")\n",
    "            sys.exit()\n",
    "    \n",
    "    def getFeatureData(self):\n",
    "        UserFeature_data = []\n",
    "        filePath_U = '../data/MVMTMDA/lncRNA-miRNA_id.txt'\n",
    "        UF_len = 0\n",
    "        with open(filePath_U,'r') as f_u:\n",
    "            for line in f_u:\n",
    "                if line:\n",
    "                    lines = line[:-1].split(\"::\")\n",
    "                    user = int(lines[1])\n",
    "                    user_f = int(lines[0])\n",
    "                    score = float(lines[2])\n",
    "                    UserFeature_data.append((user,user_f,score))\n",
    "                    if user_f > UF_len:\n",
    "                        UF_len = user_f\n",
    "        print(\"Loading Feature Success! \\n\"\n",
    "                  \"\\tUser feature length: {}\\n\".format(UF_len))\n",
    "        return UserFeature_data, UF_len\n",
    "\n",
    "    def getTrainTest(self, Testinglist):\n",
    "        data = self.data\n",
    "        train = []\n",
    "        test = []\n",
    "        for i in range(len(data)):             \n",
    "            user = data[i][0]-1\n",
    "            item = data[i][1]-1\n",
    "            rate = data[i][2]\n",
    "            if i in Testinglist:\n",
    "                test.append((user, item, rate))            \n",
    "            else:\n",
    "                train.append((user, item, rate))        \n",
    "        return train, test\n",
    "    \n",
    "\n",
    "    def getTrainDict(self):\n",
    "        dataDict = {}\n",
    "        for i in self.train:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "    \n",
    "    def getTestDict(self):\n",
    "        dataDict = {}\n",
    "        for i in self.test:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "\n",
    "    def getEmbedding(self):\n",
    "        train_matrix = np.zeros([self.shape[0], self.shape[1]], dtype=np.float32)\n",
    "        for i in self.train:\n",
    "            user = i[0]\n",
    "            movie = i[1]\n",
    "            rating = i[2]\n",
    "            train_matrix[user][movie] = rating\n",
    "        return np.array(train_matrix)\n",
    "    \n",
    "    def getFeatureEmbedding(self):\n",
    "        UserFeature_matrix = np.zeros([self.shape[0], self.UF_len], dtype=np.float32) \n",
    "        \n",
    "        for i in self.userdata:\n",
    "            user = i[0]-1\n",
    "            u_feature = i[1]-1\n",
    "            rating = i[2]\n",
    "            UserFeature_matrix[user][u_feature] = rating\n",
    "            \n",
    "        \n",
    "        return np.array(UserFeature_matrix)\n",
    "\n",
    "    def getInstances(self, data, negNum):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for i in data:\n",
    "            user.append(i[0])\n",
    "            item.append(i[1])\n",
    "            rate.append(i[2])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (i[0], j) in self.trainDict:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                user.append(i[0])\n",
    "                item.append(j)\n",
    "                rate.append(0.0)\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "    \n",
    "    #getTrainAll: return training data along with other candidates\n",
    "    def getTrainAll(self):\n",
    "        TrainDict = self.getTrainDict()\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for i in range(self.shape[0]):\n",
    "            for j in range(self.shape[1]):\n",
    "                user.append(i)\n",
    "                item.append(j)\n",
    "                if (i,j) in TrainDict:\n",
    "                    rate.append(1)\n",
    "                else:\n",
    "                    rate.append(0)\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "\n",
    "    #negNum: number of negative samples for each user\n",
    "    def getTestNeg(self, testData, negNum):\n",
    "        user = []\n",
    "        item = []\n",
    "        for s in testData:\n",
    "            tmp_user = []\n",
    "            tmp_item = []\n",
    "            u = s[0]\n",
    "            i = s[1]\n",
    "            tmp_user.append(u)\n",
    "            tmp_item.append(i)\n",
    "            neglist = set()\n",
    "            neglist.add(i)\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (u, j) in self.trainDict or j in neglist:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                neglist.add(j)\n",
    "                tmp_user.append(u)\n",
    "                tmp_item.append(j)\n",
    "            user.append(tmp_user)\n",
    "            item.append(tmp_item)\n",
    "        return [np.array(user), np.array(item)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, args, Testinglist):\n",
    "        self.dataName = args.dataName\n",
    "        self.dataSet = DataSet(self.dataName, Testinglist)\n",
    "        self.shape = self.dataSet.shape\n",
    "        self.maxRate = self.dataSet.maxRate\n",
    "        \n",
    "        self.userFlen = self.dataSet.UF_len\n",
    "        self.allMatrix = self.dataSet.getTrainAll()\n",
    "        \n",
    "        self.train = self.dataSet.train\n",
    "        self.test = self.dataSet.test\n",
    "\n",
    "        self.negNum = args.negNum\n",
    "        self.reg = args.reg\n",
    "        self.alfha = args.alfha\n",
    "        self.testNeg = self.dataSet.getTestNeg(self.test, 20)\n",
    "        \n",
    "        self.cvfold_num = args.cvfold\n",
    "        \n",
    "        self.add_embedding_matrix()\n",
    "        print(\"add_embedding_matrix SUCCESS\")\n",
    "        self.add_placeholders()\n",
    "        print(\"add_placeholders SUCCESS\")\n",
    "\n",
    "        self.userLayer = args.userLayer\n",
    "        self.itemLayer = args.itemLayer\n",
    "        self.userFLayer = args.userFLayer\n",
    "        self.add_model()\n",
    "        print(\"add_model SUCCESS\")\n",
    "\n",
    "        self.add_loss()\n",
    "        print(\"add_loss SUCCESS\")\n",
    "\n",
    "        self.lr = args.lr\n",
    "        self.add_train_step()\n",
    "        print(\"add_train_step SUCCESS\")\n",
    "\n",
    "#         self.checkPoint = args.checkPoint\n",
    "        self.init_sess()\n",
    "        print(\"init_sess SUCCESS\")\n",
    "\n",
    "        self.maxEpochs = args.maxEpochs\n",
    "        self.batchSize = args.batchSize\n",
    "\n",
    "        self.topK = args.topK\n",
    "        self.earlyStop = args.earlyStop\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.user = tf.placeholder(tf.int32)\n",
    "        self.item = tf.placeholder(tf.int32)\n",
    "        self.rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    def add_embedding_matrix(self):\n",
    "        self.user_item_embedding = tf.convert_to_tensor(self.dataSet.getEmbedding())\n",
    "        self.item_user_embedding = tf.transpose(self.user_item_embedding)\n",
    "        user_feature = self.dataSet.getFeatureEmbedding()\n",
    "        self.user_feature_embedding = tf.convert_to_tensor(user_feature)\n",
    "        self.feature_user_embedding = tf.transpose(tf.convert_to_tensor(user_feature))\n",
    "\n",
    "    def add_model(self):\n",
    "        user_input = tf.nn.embedding_lookup(self.user_item_embedding, self.user)\n",
    "        item_input = tf.nn.embedding_lookup(self.item_user_embedding, self.item)\n",
    "        Fea_user_input = self.feature_user_embedding\n",
    "        userFea_input = tf.nn.embedding_lookup(self.user_feature_embedding, self.user) \n",
    "\n",
    "        def init_variable(shape, name):\n",
    "            return tf.Variable(tf.truncated_normal(shape=shape, dtype=tf.float32, stddev=0.01), name=name)\n",
    "\n",
    "        with tf.name_scope(\"User_Layer\"):\n",
    "            user_W1 = init_variable([self.shape[1], self.userLayer[0]], \"user_W1\")\n",
    "            user_out = tf.matmul(user_input, user_W1)\n",
    "            for i in range(0, len(self.userLayer)-1):\n",
    "                W = init_variable([self.userLayer[i], self.userLayer[i+1]], \"user_W\"+str(i+2))\n",
    "                b = init_variable([self.userLayer[i+1]], \"user_b\"+str(i+2))\n",
    "                user_out = tf.nn.relu(tf.add(tf.matmul(user_out, W), b))\n",
    "\n",
    "        with tf.name_scope(\"Item_Layer\"):\n",
    "            item_W1 = init_variable([self.shape[0], self.itemLayer[0]], \"item_W1\")\n",
    "            item_out = tf.matmul(item_input, item_W1)\n",
    "            for i in range(0, len(self.itemLayer)-1):\n",
    "                W = init_variable([self.itemLayer[i], self.itemLayer[i+1]], \"item_W\"+str(i+2))\n",
    "                b = init_variable([self.itemLayer[i+1]], \"item_b\"+str(i+2))\n",
    "                item_out = tf.nn.relu(tf.add(tf.matmul(item_out, W), b))\n",
    "\n",
    "        with tf.name_scope(\"UserFeature_Layer\"):\n",
    "            userF_W1 = init_variable([self.shape[0], self.userFLayer[0]], \"userF_W1\")\n",
    "            userF_out = tf.matmul(Fea_user_input, userF_W1)\n",
    "            for i in range(0, len(self.userFLayer)-1):\n",
    "                W = init_variable([self.userFLayer[i], self.userFLayer[i+1]], \"userF_W\"+str(i+2))\n",
    "                b = init_variable([self.userFLayer[i+1]], \"userF_b\"+str(i+2))\n",
    "                userF_out = tf.nn.relu(tf.add(tf.matmul(userF_out, W), b))                \n",
    "        \n",
    "        norm_user_output = tf.norm(user_out, axis=1)\n",
    "        norm_item_output = tf.norm(item_out, axis=1)        \n",
    "        norm_userF_output = tf.norm(userF_out)\n",
    "        \n",
    "        self.y_ = tf.reduce_sum(tf.multiply(user_out, item_out), axis=1, keep_dims=False) / (norm_item_output* norm_user_output)        \n",
    "               \n",
    "        self.user_out = user_out\n",
    "        self.yu_ = tf.matmul(userF_out, tf.transpose(user_out)) / (norm_user_output* norm_userF_output)             \n",
    "        \n",
    "        self.y_ = tf.maximum(1e-6, self.y_)\n",
    "        self.yu_ = tf.maximum(1e-6, self.yu_)\n",
    "                \n",
    "        self.y_ = tf.minimum(1-1e-6, self.y_)\n",
    "        self.yu_ = tf.minimum(1-1e-6, self.yu_)\n",
    "                \n",
    "        self.yu_temp = tf.subtract(self.yu_, tf.transpose(userFea_input))\n",
    "\n",
    "    def add_loss(self):\n",
    "        regRate = self.rate / self.maxRate\n",
    "             \n",
    "        losses = regRate * tf.log(self.y_) + (1 - regRate) * tf.log(1 - self.y_)\n",
    "        loss = -tf.reduce_sum(losses)\n",
    "\n",
    "        #MSE\n",
    "        losses_u = tf.reduce_mean(tf.square(self.yu_temp)) / self.dataSet.UF_len\n",
    "        t_vars = tf.trainable_variables()\n",
    "        self.loss = loss * self.alfha + self.reg * tf.add_n([tf.nn.l2_loss(v) for v in t_vars if v.name.startswith('Item_Layer')]) + 0.5 * tf.add_n([tf.nn.l2_loss(v) for v in t_vars if v.name.startswith('User_Layer')])\n",
    "        self.loss_u = losses_u * (1-self.alfha) + self.reg * tf.add_n([tf.nn.l2_loss(v) for v in t_vars if v.name.startswith('UserFeature_Layer')]) + 0.5 * tf.add_n([tf.nn.l2_loss(v) for v in t_vars if v.name.startswith('User_Layer')])\n",
    "    def add_train_step(self):\n",
    "        '''\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(self.lr, global_step,\n",
    "                                             self.decay_steps, self.decay_rate, staircase=True)\n",
    "        '''\n",
    "        t_vars = tf.trainable_variables()\n",
    "        var_list1 = []\n",
    "        var_list2 = []\n",
    "        for v in t_vars:\n",
    "            if v.name.startswith('Item_Layer') or v.name.startswith('User_Layer'):\n",
    "                var_list2.append(v)\n",
    "        for v in t_vars:\n",
    "            if v.name.startswith('UserFeature_Layer') or v.name.startswith('User_Layer'):\n",
    "                var_list1.append(v)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_step1 = optimizer.minimize(self.loss_u, var_list = var_list1)\n",
    "        self.train_step2 = optimizer.minimize(self.loss, var_list = var_list2)\n",
    "\n",
    "    def init_sess(self):\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.config.allow_soft_placement = True\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        loss_epoch = []\n",
    "        loss_u_epoch = []\n",
    "        print(\"Start Training!\")\n",
    "        for epoch in range(self.maxEpochs):\n",
    "            print(\"=\"*20+\"Epoch \", epoch, \"=\"*20)\n",
    "            loss, loss_u = self.run_epoch(self.sess)\n",
    "            loss_epoch.append(loss)\n",
    "            loss_u_epoch.append(loss_u)\n",
    "            print('='*50)\n",
    "        s_ItemUser, s_UserF, s_UserEmbedding = self.get_testScore(self.sess)\n",
    "        return s_ItemUser, s_UserF, s_UserEmbedding\n",
    "\n",
    "    def run_epoch(self, sess, verbose=10):\n",
    "        train_u, train_i, train_r = self.dataSet.getInstances(self.train, self.negNum)\n",
    "        train_len = len(train_u)\n",
    "        shuffled_idx = np.random.permutation(np.arange(train_len))\n",
    "        train_u = train_u[shuffled_idx]\n",
    "        train_i = train_i[shuffled_idx]\n",
    "        train_r = train_r[shuffled_idx]\n",
    "\n",
    "        num_batches = len(train_u) // self.batchSize + 1\n",
    "\n",
    "        losses = []\n",
    "        losses_u = []\n",
    "        for i in range(num_batches):\n",
    "            min_idx = i * self.batchSize\n",
    "            max_idx = np.min([train_len, (i+1)*self.batchSize])\n",
    "            train_u_batch = train_u[min_idx: max_idx]\n",
    "            train_i_batch = train_i[min_idx: max_idx]\n",
    "            train_r_batch = train_r[min_idx: max_idx]\n",
    "\n",
    "            feed_dict = self.create_feed_dict(train_u_batch, train_i_batch, train_r_batch)\n",
    "            _, _, tmp_loss, tmp_loss_u = sess.run([self.train_step1, self.train_step2, self.loss, self.loss_u], feed_dict=feed_dict)\n",
    "#             _, tmp_loss, tmp_loss_u = sess.run([self.train_step2, self.loss, self.loss_u], feed_dict=feed_dict)\n",
    "            losses.append(tmp_loss)\n",
    "            losses_u.append(tmp_loss_u)\n",
    "            if verbose and i % verbose == 0:\n",
    "                if np.isnan(np.mean(losses[-verbose:])):\n",
    "                    raise ValueError                                \n",
    "                sys.stdout.write('\\r{} / {} : loss = {}'.format(\n",
    "                    i, num_batches, np.mean(losses[-verbose:])\n",
    "                ))\n",
    "                sys.stdout.flush()\n",
    "        loss = np.mean(losses)\n",
    "        loss_u = np.mean(losses_u)\n",
    "        print(\"\\nMean loss in this epoch is: {}\".format(loss))\n",
    "        return loss, loss_u\n",
    "\n",
    "    def create_feed_dict(self, u, i, r=None):\n",
    "        return {self.user: u,\n",
    "                self.item: i,\n",
    "                self.rate: r,}\n",
    "\n",
    "    def evaluate(self, sess, topK):\n",
    "        def getHitRatio(ranklist, targetItem):\n",
    "            for item in ranklist:\n",
    "                if item == targetItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "        def getNDCG(ranklist, targetItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == targetItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "\n",
    "        hr =[]\n",
    "        NDCG = []\n",
    "        testUser = self.testNeg[0]\n",
    "        testItem = self.testNeg[1]\n",
    "        for i in range(len(testUser)):\n",
    "            target = testItem[i][0]\n",
    "            feed_dict = self.create_feed_dict(testUser[i], testItem[i])\n",
    "            predict = sess.run(self.y_, feed_dict=feed_dict)\n",
    "            item_score_dict = {}\n",
    "\n",
    "            for j in range(len(testItem[i])):\n",
    "                item = testItem[i][j]\n",
    "                item_score_dict[item] = predict[j]\n",
    "\n",
    "            ranklist = heapq.nlargest(topK, item_score_dict, key=item_score_dict.get)\n",
    "\n",
    "            tmp_hr = getHitRatio(ranklist, target)\n",
    "            tmp_NDCG = getNDCG(ranklist, target)\n",
    "            hr.append(tmp_hr)\n",
    "            NDCG.append(tmp_NDCG)\n",
    "        return np.mean(hr), np.mean(NDCG)\n",
    "    \n",
    "    def get_testScore(self, sess):\n",
    "        train_allu = self.allMatrix[0]\n",
    "        train_alli = self.allMatrix[1]\n",
    "        train_allr = self.allMatrix[2]\n",
    "        feed_dict = self.create_feed_dict(train_allu, train_alli, train_allr)\n",
    "        predict_p, predict_q, predict_user_out = sess.run([self.y_, self.yu_, self.user_out], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        s_ItemUser = np.zeros((799, 268))\n",
    "        for i in range(len(predict_p)):\n",
    "            s_ItemUser[train_alli[i],train_allu[i]] = predict_p[i]\n",
    "        \n",
    "        \n",
    "        print(predict_user_out.shape)\n",
    "        s_UserEmbedding = np.zeros((268, predict_user_out.shape[1]))\n",
    "         #to get the score of userFeature matrix        \n",
    "        s_UserF = np.zeros((541, 268))\n",
    "        u_set = set()\n",
    "        for i in range(predict_q.shape[1]):\n",
    "            if train_allu[i] not in u_set:\n",
    "                s_UserF[:,train_allu[i]] = predict_q[:, i]\n",
    "                s_UserEmbedding[train_allu[i],:] = predict_user_out[i, :]\n",
    "                u_set.add(train_allu[i])\n",
    "        \n",
    "        return s_ItemUser, s_UserF, s_UserEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lncRNA-miRNA data set...\n",
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 268\n",
      "\tItem Num: 799\n",
      "\tData Size: 11252\n",
      "Loading Feature Success! \n",
      "\tUser feature length: 541\n",
      "\n",
      "add_embedding_matrix SUCCESS\n",
      "add_placeholders SUCCESS\n",
      "add_model SUCCESS\n",
      "add_loss SUCCESS\n",
      "add_train_step SUCCESS\n",
      "init_sess SUCCESS\n",
      "Start Training!\n",
      "====================Epoch  0 ====================\n",
      "0 / 5 : loss = 2462.306884765625\n",
      "Mean loss in this epoch is: 2203.274658203125\n",
      "==================================================\n",
      "====================Epoch  1 ====================\n",
      "0 / 5 : loss = 2406.5283203125\n",
      "Mean loss in this epoch is: 2151.822509765625\n",
      "==================================================\n",
      "====================Epoch  2 ====================\n",
      "0 / 5 : loss = 2357.778564453125\n",
      "Mean loss in this epoch is: 2111.03076171875\n",
      "==================================================\n",
      "====================Epoch  3 ====================\n",
      "0 / 5 : loss = 2328.205810546875\n",
      "Mean loss in this epoch is: 2069.09326171875\n",
      "==================================================\n",
      "====================Epoch  4 ====================\n",
      "0 / 5 : loss = 2271.385986328125\n",
      "Mean loss in this epoch is: 2027.302734375\n",
      "==================================================\n",
      "====================Epoch  5 ====================\n",
      "0 / 5 : loss = 2220.7919921875\n",
      "Mean loss in this epoch is: 1981.0947265625\n",
      "==================================================\n",
      "====================Epoch  6 ====================\n",
      "0 / 5 : loss = 2174.8876953125\n",
      "Mean loss in this epoch is: 1940.531494140625\n",
      "==================================================\n",
      "====================Epoch  7 ====================\n",
      "0 / 5 : loss = 2119.95263671875\n",
      "Mean loss in this epoch is: 1894.327392578125\n",
      "==================================================\n",
      "====================Epoch  8 ====================\n",
      "0 / 5 : loss = 2079.9033203125\n",
      "Mean loss in this epoch is: 1857.404541015625\n",
      "==================================================\n",
      "====================Epoch  9 ====================\n",
      "0 / 5 : loss = 2027.9027099609375\n",
      "Mean loss in this epoch is: 1821.395751953125\n",
      "==================================================\n",
      "====================Epoch  10 ====================\n",
      "0 / 5 : loss = 1998.4742431640625\n",
      "Mean loss in this epoch is: 1779.6068115234375\n",
      "==================================================\n",
      "====================Epoch  11 ====================\n",
      "0 / 5 : loss = 1962.4334716796875\n",
      "Mean loss in this epoch is: 1751.645751953125\n",
      "==================================================\n",
      "====================Epoch  12 ====================\n",
      "0 / 5 : loss = 1909.7469482421875\n",
      "Mean loss in this epoch is: 1713.584716796875\n",
      "==================================================\n",
      "====================Epoch  13 ====================\n",
      "0 / 5 : loss = 1880.0570068359375\n",
      "Mean loss in this epoch is: 1688.450439453125\n",
      "==================================================\n",
      "====================Epoch  14 ====================\n",
      "0 / 5 : loss = 1845.95654296875\n",
      "Mean loss in this epoch is: 1666.3001708984375\n",
      "==================================================\n",
      "====================Epoch  15 ====================\n",
      "0 / 5 : loss = 1804.56787109375\n",
      "Mean loss in this epoch is: 1635.2431640625\n",
      "==================================================\n",
      "====================Epoch  16 ====================\n",
      "0 / 5 : loss = 1778.8060302734375\n",
      "Mean loss in this epoch is: 1614.951416015625\n",
      "==================================================\n",
      "====================Epoch  17 ====================\n",
      "0 / 5 : loss = 1767.468505859375\n",
      "Mean loss in this epoch is: 1598.9447021484375\n",
      "==================================================\n",
      "====================Epoch  18 ====================\n",
      "0 / 5 : loss = 1796.65966796875\n",
      "Mean loss in this epoch is: 1588.1134033203125\n",
      "==================================================\n",
      "====================Epoch  19 ====================\n",
      "0 / 5 : loss = 1755.2703857421875\n",
      "Mean loss in this epoch is: 1567.001708984375\n",
      "==================================================\n",
      "====================Epoch  20 ====================\n",
      "0 / 5 : loss = 1763.8851318359375\n",
      "Mean loss in this epoch is: 1566.4425048828125\n",
      "==================================================\n",
      "====================Epoch  21 ====================\n",
      "0 / 5 : loss = 1702.21435546875\n",
      "Mean loss in this epoch is: 1548.0849609375\n",
      "==================================================\n",
      "====================Epoch  22 ====================\n",
      "0 / 5 : loss = 1701.469970703125\n",
      "Mean loss in this epoch is: 1533.102783203125\n",
      "==================================================\n",
      "====================Epoch  23 ====================\n",
      "0 / 5 : loss = 1712.527587890625\n",
      "Mean loss in this epoch is: 1534.39306640625\n",
      "==================================================\n",
      "====================Epoch  24 ====================\n",
      "0 / 5 : loss = 1717.6495361328125\n",
      "Mean loss in this epoch is: 1521.1661376953125\n",
      "==================================================\n",
      "====================Epoch  25 ====================\n",
      "0 / 5 : loss = 1686.5631103515625\n",
      "Mean loss in this epoch is: 1513.3751220703125\n",
      "==================================================\n",
      "====================Epoch  26 ====================\n",
      "0 / 5 : loss = 1693.7139892578125\n",
      "Mean loss in this epoch is: 1514.8336181640625\n",
      "==================================================\n",
      "====================Epoch  27 ====================\n",
      "0 / 5 : loss = 1619.8248291015625\n",
      "Mean loss in this epoch is: 1496.48291015625\n",
      "==================================================\n",
      "====================Epoch  28 ====================\n",
      "0 / 5 : loss = 1656.251953125\n",
      "Mean loss in this epoch is: 1491.4163818359375\n",
      "==================================================\n",
      "====================Epoch  29 ====================\n",
      "0 / 5 : loss = 1644.92822265625\n",
      "Mean loss in this epoch is: 1488.819091796875\n",
      "==================================================\n",
      "====================Epoch  30 ====================\n",
      "0 / 5 : loss = 1651.37109375\n",
      "Mean loss in this epoch is: 1471.8316650390625\n",
      "==================================================\n",
      "====================Epoch  31 ====================\n",
      "0 / 5 : loss = 1643.463623046875\n",
      "Mean loss in this epoch is: 1465.2418212890625\n",
      "==================================================\n",
      "====================Epoch  32 ====================\n",
      "0 / 5 : loss = 1603.727783203125\n",
      "Mean loss in this epoch is: 1473.758544921875\n",
      "==================================================\n",
      "====================Epoch  33 ====================\n",
      "0 / 5 : loss = 1616.509033203125\n",
      "Mean loss in this epoch is: 1467.517822265625\n",
      "==================================================\n",
      "====================Epoch  34 ====================\n",
      "0 / 5 : loss = 1612.3631591796875\n",
      "Mean loss in this epoch is: 1456.04296875\n",
      "==================================================\n",
      "====================Epoch  35 ====================\n",
      "0 / 5 : loss = 1625.79345703125\n",
      "Mean loss in this epoch is: 1470.306640625\n",
      "==================================================\n",
      "====================Epoch  36 ====================\n",
      "0 / 5 : loss = 1617.3043212890625\n",
      "Mean loss in this epoch is: 1456.7489013671875\n",
      "==================================================\n",
      "====================Epoch  37 ====================\n",
      "0 / 5 : loss = 1621.2620849609375\n",
      "Mean loss in this epoch is: 1457.259033203125\n",
      "==================================================\n",
      "====================Epoch  38 ====================\n",
      "0 / 5 : loss = 1624.3289794921875\n",
      "Mean loss in this epoch is: 1467.596435546875\n",
      "==================================================\n",
      "====================Epoch  39 ====================\n",
      "0 / 5 : loss = 1663.460693359375\n",
      "Mean loss in this epoch is: 1453.70458984375\n",
      "==================================================\n",
      "====================Epoch  40 ====================\n",
      "0 / 5 : loss = 1585.641357421875\n",
      "Mean loss in this epoch is: 1444.8154296875\n",
      "==================================================\n",
      "====================Epoch  41 ====================\n",
      "0 / 5 : loss = 1618.343505859375\n",
      "Mean loss in this epoch is: 1445.089599609375\n",
      "==================================================\n",
      "====================Epoch  42 ====================\n",
      "0 / 5 : loss = 1614.65869140625\n",
      "Mean loss in this epoch is: 1451.79345703125\n",
      "==================================================\n",
      "====================Epoch  43 ====================\n",
      "0 / 5 : loss = 1581.599365234375\n",
      "Mean loss in this epoch is: 1427.695556640625\n",
      "==================================================\n",
      "====================Epoch  44 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1576.15966796875\n",
      "Mean loss in this epoch is: 1432.8233642578125\n",
      "==================================================\n",
      "====================Epoch  45 ====================\n",
      "0 / 5 : loss = 1590.4786376953125\n",
      "Mean loss in this epoch is: 1432.787353515625\n",
      "==================================================\n",
      "====================Epoch  46 ====================\n",
      "0 / 5 : loss = 1582.446044921875\n",
      "Mean loss in this epoch is: 1426.0816650390625\n",
      "==================================================\n",
      "====================Epoch  47 ====================\n",
      "0 / 5 : loss = 1596.2276611328125\n",
      "Mean loss in this epoch is: 1446.6546630859375\n",
      "==================================================\n",
      "====================Epoch  48 ====================\n",
      "0 / 5 : loss = 1608.1014404296875\n",
      "Mean loss in this epoch is: 1429.98193359375\n",
      "==================================================\n",
      "====================Epoch  49 ====================\n",
      "0 / 5 : loss = 1599.5155029296875\n",
      "Mean loss in this epoch is: 1438.635009765625\n",
      "==================================================\n",
      "====================Epoch  50 ====================\n",
      "0 / 5 : loss = 1637.6826171875\n",
      "Mean loss in this epoch is: 1445.18701171875\n",
      "==================================================\n",
      "====================Epoch  51 ====================\n",
      "0 / 5 : loss = 1551.03076171875\n",
      "Mean loss in this epoch is: 1427.6322021484375\n",
      "==================================================\n",
      "====================Epoch  52 ====================\n",
      "0 / 5 : loss = 1604.0732421875\n",
      "Mean loss in this epoch is: 1431.009033203125\n",
      "==================================================\n",
      "====================Epoch  53 ====================\n",
      "0 / 5 : loss = 1612.676025390625\n",
      "Mean loss in this epoch is: 1441.240966796875\n",
      "==================================================\n",
      "====================Epoch  54 ====================\n",
      "0 / 5 : loss = 1622.7203369140625\n",
      "Mean loss in this epoch is: 1431.070068359375\n",
      "==================================================\n",
      "====================Epoch  55 ====================\n",
      "0 / 5 : loss = 1562.501220703125\n",
      "Mean loss in this epoch is: 1421.040283203125\n",
      "==================================================\n",
      "====================Epoch  56 ====================\n",
      "0 / 5 : loss = 1590.158935546875\n",
      "Mean loss in this epoch is: 1415.552490234375\n",
      "==================================================\n",
      "====================Epoch  57 ====================\n",
      "0 / 5 : loss = 1559.31201171875\n",
      "Mean loss in this epoch is: 1419.3868408203125\n",
      "==================================================\n",
      "====================Epoch  58 ====================\n",
      "0 / 5 : loss = 1618.4619140625\n",
      "Mean loss in this epoch is: 1420.32373046875\n",
      "==================================================\n",
      "====================Epoch  59 ====================\n",
      "0 / 5 : loss = 1587.4193115234375\n",
      "Mean loss in this epoch is: 1423.015869140625\n",
      "==================================================\n",
      "====================Epoch  60 ====================\n",
      "0 / 5 : loss = 1522.949462890625\n",
      "Mean loss in this epoch is: 1419.6131591796875\n",
      "==================================================\n",
      "====================Epoch  61 ====================\n",
      "0 / 5 : loss = 1574.1385498046875\n",
      "Mean loss in this epoch is: 1419.765869140625\n",
      "==================================================\n",
      "====================Epoch  62 ====================\n",
      "0 / 5 : loss = 1566.2987060546875\n",
      "Mean loss in this epoch is: 1420.798583984375\n",
      "==================================================\n",
      "====================Epoch  63 ====================\n",
      "0 / 5 : loss = 1597.8870849609375\n",
      "Mean loss in this epoch is: 1432.9755859375\n",
      "==================================================\n",
      "====================Epoch  64 ====================\n",
      "0 / 5 : loss = 1571.538330078125\n",
      "Mean loss in this epoch is: 1405.7254638671875\n",
      "==================================================\n",
      "====================Epoch  65 ====================\n",
      "0 / 5 : loss = 1581.1041259765625\n",
      "Mean loss in this epoch is: 1401.30712890625\n",
      "==================================================\n",
      "====================Epoch  66 ====================\n",
      "0 / 5 : loss = 1593.3017578125\n",
      "Mean loss in this epoch is: 1420.615966796875\n",
      "==================================================\n",
      "====================Epoch  67 ====================\n",
      "0 / 5 : loss = 1557.102294921875\n",
      "Mean loss in this epoch is: 1410.8924560546875\n",
      "==================================================\n",
      "====================Epoch  68 ====================\n",
      "0 / 5 : loss = 1535.391357421875\n",
      "Mean loss in this epoch is: 1408.9013671875\n",
      "==================================================\n",
      "====================Epoch  69 ====================\n",
      "0 / 5 : loss = 1562.3592529296875\n",
      "Mean loss in this epoch is: 1419.8916015625\n",
      "==================================================\n",
      "====================Epoch  70 ====================\n",
      "0 / 5 : loss = 1579.896484375\n",
      "Mean loss in this epoch is: 1395.4549560546875\n",
      "==================================================\n",
      "====================Epoch  71 ====================\n",
      "0 / 5 : loss = 1578.0340576171875\n",
      "Mean loss in this epoch is: 1400.5211181640625\n",
      "==================================================\n",
      "====================Epoch  72 ====================\n",
      "0 / 5 : loss = 1566.1595458984375\n",
      "Mean loss in this epoch is: 1415.1514892578125\n",
      "==================================================\n",
      "====================Epoch  73 ====================\n",
      "0 / 5 : loss = 1568.1041259765625\n",
      "Mean loss in this epoch is: 1409.0325927734375\n",
      "==================================================\n",
      "====================Epoch  74 ====================\n",
      "0 / 5 : loss = 1543.3221435546875\n",
      "Mean loss in this epoch is: 1407.591796875\n",
      "==================================================\n",
      "====================Epoch  75 ====================\n",
      "0 / 5 : loss = 1596.4608154296875\n",
      "Mean loss in this epoch is: 1407.1544189453125\n",
      "==================================================\n",
      "====================Epoch  76 ====================\n",
      "0 / 5 : loss = 1542.6312255859375\n",
      "Mean loss in this epoch is: 1403.5618896484375\n",
      "==================================================\n",
      "====================Epoch  77 ====================\n",
      "0 / 5 : loss = 1567.8170166015625\n",
      "Mean loss in this epoch is: 1402.02490234375\n",
      "==================================================\n",
      "====================Epoch  78 ====================\n",
      "0 / 5 : loss = 1539.6236572265625\n",
      "Mean loss in this epoch is: 1398.93994140625\n",
      "==================================================\n",
      "====================Epoch  79 ====================\n",
      "0 / 5 : loss = 1600.397216796875\n",
      "Mean loss in this epoch is: 1401.776611328125\n",
      "==================================================\n",
      "====================Epoch  80 ====================\n",
      "0 / 5 : loss = 1576.521728515625\n",
      "Mean loss in this epoch is: 1423.185791015625\n",
      "==================================================\n",
      "====================Epoch  81 ====================\n",
      "0 / 5 : loss = 1603.37744140625\n",
      "Mean loss in this epoch is: 1396.2254638671875\n",
      "==================================================\n",
      "====================Epoch  82 ====================\n",
      "0 / 5 : loss = 1523.4803466796875\n",
      "Mean loss in this epoch is: 1390.0926513671875\n",
      "==================================================\n",
      "====================Epoch  83 ====================\n",
      "0 / 5 : loss = 1577.4796142578125\n",
      "Mean loss in this epoch is: 1393.3472900390625\n",
      "==================================================\n",
      "====================Epoch  84 ====================\n",
      "0 / 5 : loss = 1570.68603515625\n",
      "Mean loss in this epoch is: 1404.987060546875\n",
      "==================================================\n",
      "====================Epoch  85 ====================\n",
      "0 / 5 : loss = 1547.8145751953125\n",
      "Mean loss in this epoch is: 1393.853759765625\n",
      "==================================================\n",
      "====================Epoch  86 ====================\n",
      "0 / 5 : loss = 1488.074462890625\n",
      "Mean loss in this epoch is: 1379.814208984375\n",
      "==================================================\n",
      "====================Epoch  87 ====================\n",
      "0 / 5 : loss = 1539.004150390625\n",
      "Mean loss in this epoch is: 1391.6954345703125\n",
      "==================================================\n",
      "====================Epoch  88 ====================\n",
      "0 / 5 : loss = 1536.6029052734375\n",
      "Mean loss in this epoch is: 1398.302001953125\n",
      "==================================================\n",
      "====================Epoch  89 ====================\n",
      "0 / 5 : loss = 1562.75732421875\n",
      "Mean loss in this epoch is: 1400.949462890625\n",
      "==================================================\n",
      "====================Epoch  90 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1548.1566162109375\n",
      "Mean loss in this epoch is: 1380.616943359375\n",
      "==================================================\n",
      "====================Epoch  91 ====================\n",
      "0 / 5 : loss = 1535.3759765625\n",
      "Mean loss in this epoch is: 1393.246337890625\n",
      "==================================================\n",
      "====================Epoch  92 ====================\n",
      "0 / 5 : loss = 1549.5693359375\n",
      "Mean loss in this epoch is: 1382.20849609375\n",
      "==================================================\n",
      "====================Epoch  93 ====================\n",
      "0 / 5 : loss = 1523.0936279296875\n",
      "Mean loss in this epoch is: 1388.0684814453125\n",
      "==================================================\n",
      "====================Epoch  94 ====================\n",
      "0 / 5 : loss = 1596.04736328125\n",
      "Mean loss in this epoch is: 1386.61181640625\n",
      "==================================================\n",
      "====================Epoch  95 ====================\n",
      "0 / 5 : loss = 1536.0911865234375\n",
      "Mean loss in this epoch is: 1398.893798828125\n",
      "==================================================\n",
      "====================Epoch  96 ====================\n",
      "0 / 5 : loss = 1522.9698486328125\n",
      "Mean loss in this epoch is: 1395.9298095703125\n",
      "==================================================\n",
      "====================Epoch  97 ====================\n",
      "0 / 5 : loss = 1577.75634765625\n",
      "Mean loss in this epoch is: 1401.0877685546875\n",
      "==================================================\n",
      "====================Epoch  98 ====================\n",
      "0 / 5 : loss = 1542.5513916015625\n",
      "Mean loss in this epoch is: 1395.37841796875\n",
      "==================================================\n",
      "====================Epoch  99 ====================\n",
      "0 / 5 : loss = 1527.7738037109375\n",
      "Mean loss in this epoch is: 1394.23193359375\n",
      "==================================================\n",
      "====================Epoch  100 ====================\n",
      "0 / 5 : loss = 1500.981201171875\n",
      "Mean loss in this epoch is: 1374.21826171875\n",
      "==================================================\n",
      "====================Epoch  101 ====================\n",
      "0 / 5 : loss = 1521.3812255859375\n",
      "Mean loss in this epoch is: 1403.4593505859375\n",
      "==================================================\n",
      "====================Epoch  102 ====================\n",
      "0 / 5 : loss = 1543.0703125\n",
      "Mean loss in this epoch is: 1388.6036376953125\n",
      "==================================================\n",
      "====================Epoch  103 ====================\n",
      "0 / 5 : loss = 1529.16650390625\n",
      "Mean loss in this epoch is: 1387.266845703125\n",
      "==================================================\n",
      "====================Epoch  104 ====================\n",
      "0 / 5 : loss = 1516.9639892578125\n",
      "Mean loss in this epoch is: 1379.532958984375\n",
      "==================================================\n",
      "====================Epoch  105 ====================\n",
      "0 / 5 : loss = 1492.4700927734375\n",
      "Mean loss in this epoch is: 1385.010498046875\n",
      "==================================================\n",
      "====================Epoch  106 ====================\n",
      "0 / 5 : loss = 1494.759521484375\n",
      "Mean loss in this epoch is: 1382.75830078125\n",
      "==================================================\n",
      "====================Epoch  107 ====================\n",
      "0 / 5 : loss = 1538.084228515625\n",
      "Mean loss in this epoch is: 1387.6138916015625\n",
      "==================================================\n",
      "====================Epoch  108 ====================\n",
      "0 / 5 : loss = 1528.2593994140625\n",
      "Mean loss in this epoch is: 1376.9962158203125\n",
      "==================================================\n",
      "====================Epoch  109 ====================\n",
      "0 / 5 : loss = 1502.194580078125\n",
      "Mean loss in this epoch is: 1394.688720703125\n",
      "==================================================\n",
      "====================Epoch  110 ====================\n",
      "0 / 5 : loss = 1558.2874755859375\n",
      "Mean loss in this epoch is: 1377.284423828125\n",
      "==================================================\n",
      "====================Epoch  111 ====================\n",
      "0 / 5 : loss = 1542.305908203125\n",
      "Mean loss in this epoch is: 1386.250732421875\n",
      "==================================================\n",
      "====================Epoch  112 ====================\n",
      "0 / 5 : loss = 1576.8203125\n",
      "Mean loss in this epoch is: 1380.603759765625\n",
      "==================================================\n",
      "====================Epoch  113 ====================\n",
      "0 / 5 : loss = 1513.71142578125\n",
      "Mean loss in this epoch is: 1383.8912353515625\n",
      "==================================================\n",
      "====================Epoch  114 ====================\n",
      "0 / 5 : loss = 1547.29052734375\n",
      "Mean loss in this epoch is: 1385.5391845703125\n",
      "==================================================\n",
      "====================Epoch  115 ====================\n",
      "0 / 5 : loss = 1517.9091796875\n",
      "Mean loss in this epoch is: 1384.6767578125\n",
      "==================================================\n",
      "====================Epoch  116 ====================\n",
      "0 / 5 : loss = 1527.5257568359375\n",
      "Mean loss in this epoch is: 1368.597412109375\n",
      "==================================================\n",
      "====================Epoch  117 ====================\n",
      "0 / 5 : loss = 1510.8505859375\n",
      "Mean loss in this epoch is: 1368.5787353515625\n",
      "==================================================\n",
      "====================Epoch  118 ====================\n",
      "0 / 5 : loss = 1510.798583984375\n",
      "Mean loss in this epoch is: 1386.685546875\n",
      "==================================================\n",
      "====================Epoch  119 ====================\n",
      "0 / 5 : loss = 1522.2481689453125\n",
      "Mean loss in this epoch is: 1380.986572265625\n",
      "==================================================\n",
      "====================Epoch  120 ====================\n",
      "0 / 5 : loss = 1521.6737060546875\n",
      "Mean loss in this epoch is: 1370.924072265625\n",
      "==================================================\n",
      "====================Epoch  121 ====================\n",
      "0 / 5 : loss = 1498.314208984375\n",
      "Mean loss in this epoch is: 1372.4097900390625\n",
      "==================================================\n",
      "====================Epoch  122 ====================\n",
      "0 / 5 : loss = 1513.701904296875\n",
      "Mean loss in this epoch is: 1369.0531005859375\n",
      "==================================================\n",
      "====================Epoch  123 ====================\n",
      "0 / 5 : loss = 1551.90966796875\n",
      "Mean loss in this epoch is: 1382.7861328125\n",
      "==================================================\n",
      "====================Epoch  124 ====================\n",
      "0 / 5 : loss = 1522.06298828125\n",
      "Mean loss in this epoch is: 1375.853515625\n",
      "==================================================\n",
      "====================Epoch  125 ====================\n",
      "0 / 5 : loss = 1552.0665283203125\n",
      "Mean loss in this epoch is: 1369.461181640625\n",
      "==================================================\n",
      "====================Epoch  126 ====================\n",
      "0 / 5 : loss = 1541.07568359375\n",
      "Mean loss in this epoch is: 1376.947021484375\n",
      "==================================================\n",
      "====================Epoch  127 ====================\n",
      "0 / 5 : loss = 1506.6678466796875\n",
      "Mean loss in this epoch is: 1382.358642578125\n",
      "==================================================\n",
      "====================Epoch  128 ====================\n",
      "0 / 5 : loss = 1499.6507568359375\n",
      "Mean loss in this epoch is: 1361.8154296875\n",
      "==================================================\n",
      "====================Epoch  129 ====================\n",
      "0 / 5 : loss = 1509.542724609375\n",
      "Mean loss in this epoch is: 1368.4769287109375\n",
      "==================================================\n",
      "====================Epoch  130 ====================\n",
      "0 / 5 : loss = 1525.7623291015625\n",
      "Mean loss in this epoch is: 1390.3037109375\n",
      "==================================================\n",
      "====================Epoch  131 ====================\n",
      "0 / 5 : loss = 1515.21435546875\n",
      "Mean loss in this epoch is: 1365.585693359375\n",
      "==================================================\n",
      "====================Epoch  132 ====================\n",
      "0 / 5 : loss = 1542.344482421875\n",
      "Mean loss in this epoch is: 1371.8580322265625\n",
      "==================================================\n",
      "====================Epoch  133 ====================\n",
      "0 / 5 : loss = 1517.267333984375\n",
      "Mean loss in this epoch is: 1374.7713623046875\n",
      "==================================================\n",
      "====================Epoch  134 ====================\n",
      "0 / 5 : loss = 1526.90185546875\n",
      "Mean loss in this epoch is: 1361.112548828125\n",
      "==================================================\n",
      "====================Epoch  135 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1552.6177978515625\n",
      "Mean loss in this epoch is: 1372.9095458984375\n",
      "==================================================\n",
      "====================Epoch  136 ====================\n",
      "0 / 5 : loss = 1440.1907958984375\n",
      "Mean loss in this epoch is: 1378.277099609375\n",
      "==================================================\n",
      "====================Epoch  137 ====================\n",
      "0 / 5 : loss = 1541.543701171875\n",
      "Mean loss in this epoch is: 1350.9599609375\n",
      "==================================================\n",
      "====================Epoch  138 ====================\n",
      "0 / 5 : loss = 1506.873291015625\n",
      "Mean loss in this epoch is: 1378.952392578125\n",
      "==================================================\n",
      "====================Epoch  139 ====================\n",
      "0 / 5 : loss = 1533.8289794921875\n",
      "Mean loss in this epoch is: 1379.5863037109375\n",
      "==================================================\n",
      "====================Epoch  140 ====================\n",
      "0 / 5 : loss = 1537.4674072265625\n",
      "Mean loss in this epoch is: 1359.5386962890625\n",
      "==================================================\n",
      "====================Epoch  141 ====================\n",
      "0 / 5 : loss = 1481.281982421875\n",
      "Mean loss in this epoch is: 1370.2396240234375\n",
      "==================================================\n",
      "====================Epoch  142 ====================\n",
      "0 / 5 : loss = 1525.7745361328125\n",
      "Mean loss in this epoch is: 1371.840087890625\n",
      "==================================================\n",
      "====================Epoch  143 ====================\n",
      "0 / 5 : loss = 1554.02783203125\n",
      "Mean loss in this epoch is: 1382.167724609375\n",
      "==================================================\n",
      "====================Epoch  144 ====================\n",
      "0 / 5 : loss = 1513.766845703125\n",
      "Mean loss in this epoch is: 1366.561279296875\n",
      "==================================================\n",
      "====================Epoch  145 ====================\n",
      "0 / 5 : loss = 1560.1295166015625\n",
      "Mean loss in this epoch is: 1375.561767578125\n",
      "==================================================\n",
      "====================Epoch  146 ====================\n",
      "0 / 5 : loss = 1507.7305908203125\n",
      "Mean loss in this epoch is: 1366.31640625\n",
      "==================================================\n",
      "====================Epoch  147 ====================\n",
      "0 / 5 : loss = 1479.989990234375\n",
      "Mean loss in this epoch is: 1362.9232177734375\n",
      "==================================================\n",
      "====================Epoch  148 ====================\n",
      "0 / 5 : loss = 1494.3349609375\n",
      "Mean loss in this epoch is: 1362.5299072265625\n",
      "==================================================\n",
      "====================Epoch  149 ====================\n",
      "0 / 5 : loss = 1510.657958984375\n",
      "Mean loss in this epoch is: 1365.587646484375\n",
      "==================================================\n",
      "====================Epoch  150 ====================\n",
      "0 / 5 : loss = 1505.2562255859375\n",
      "Mean loss in this epoch is: 1359.901611328125\n",
      "==================================================\n",
      "====================Epoch  151 ====================\n",
      "0 / 5 : loss = 1525.728759765625\n",
      "Mean loss in this epoch is: 1367.3675537109375\n",
      "==================================================\n",
      "====================Epoch  152 ====================\n",
      "0 / 5 : loss = 1540.670654296875\n",
      "Mean loss in this epoch is: 1376.271728515625\n",
      "==================================================\n",
      "====================Epoch  153 ====================\n",
      "0 / 5 : loss = 1549.3582763671875\n",
      "Mean loss in this epoch is: 1373.88916015625\n",
      "==================================================\n",
      "====================Epoch  154 ====================\n",
      "0 / 5 : loss = 1517.9910888671875\n",
      "Mean loss in this epoch is: 1364.802490234375\n",
      "==================================================\n",
      "====================Epoch  155 ====================\n",
      "0 / 5 : loss = 1505.41015625\n",
      "Mean loss in this epoch is: 1355.338623046875\n",
      "==================================================\n",
      "====================Epoch  156 ====================\n",
      "0 / 5 : loss = 1567.047119140625\n",
      "Mean loss in this epoch is: 1379.2359619140625\n",
      "==================================================\n",
      "====================Epoch  157 ====================\n",
      "0 / 5 : loss = 1451.30419921875\n",
      "Mean loss in this epoch is: 1360.0496826171875\n",
      "==================================================\n",
      "====================Epoch  158 ====================\n",
      "0 / 5 : loss = 1489.8397216796875\n",
      "Mean loss in this epoch is: 1366.839599609375\n",
      "==================================================\n",
      "====================Epoch  159 ====================\n",
      "0 / 5 : loss = 1517.486328125\n",
      "Mean loss in this epoch is: 1365.12548828125\n",
      "==================================================\n",
      "====================Epoch  160 ====================\n",
      "0 / 5 : loss = 1481.3084716796875\n",
      "Mean loss in this epoch is: 1360.743408203125\n",
      "==================================================\n",
      "====================Epoch  161 ====================\n",
      "0 / 5 : loss = 1528.6524658203125\n",
      "Mean loss in this epoch is: 1356.658935546875\n",
      "==================================================\n",
      "====================Epoch  162 ====================\n",
      "0 / 5 : loss = 1540.3197021484375\n",
      "Mean loss in this epoch is: 1347.585693359375\n",
      "==================================================\n",
      "====================Epoch  163 ====================\n",
      "0 / 5 : loss = 1501.7401123046875\n",
      "Mean loss in this epoch is: 1367.13134765625\n",
      "==================================================\n",
      "====================Epoch  164 ====================\n",
      "0 / 5 : loss = 1509.3153076171875\n",
      "Mean loss in this epoch is: 1354.0150146484375\n",
      "==================================================\n",
      "====================Epoch  165 ====================\n",
      "0 / 5 : loss = 1511.6861572265625\n",
      "Mean loss in this epoch is: 1359.543212890625\n",
      "==================================================\n",
      "====================Epoch  166 ====================\n",
      "0 / 5 : loss = 1538.4647216796875\n",
      "Mean loss in this epoch is: 1358.683349609375\n",
      "==================================================\n",
      "====================Epoch  167 ====================\n",
      "0 / 5 : loss = 1498.3514404296875\n",
      "Mean loss in this epoch is: 1348.7353515625\n",
      "==================================================\n",
      "====================Epoch  168 ====================\n",
      "0 / 5 : loss = 1518.065673828125\n",
      "Mean loss in this epoch is: 1364.4678955078125\n",
      "==================================================\n",
      "====================Epoch  169 ====================\n",
      "0 / 5 : loss = 1504.2325439453125\n",
      "Mean loss in this epoch is: 1362.3349609375\n",
      "==================================================\n",
      "====================Epoch  170 ====================\n",
      "0 / 5 : loss = 1541.7845458984375\n",
      "Mean loss in this epoch is: 1359.05126953125\n",
      "==================================================\n",
      "====================Epoch  171 ====================\n",
      "0 / 5 : loss = 1498.57861328125\n",
      "Mean loss in this epoch is: 1343.2186279296875\n",
      "==================================================\n",
      "====================Epoch  172 ====================\n",
      "0 / 5 : loss = 1489.5069580078125\n",
      "Mean loss in this epoch is: 1353.57080078125\n",
      "==================================================\n",
      "====================Epoch  173 ====================\n",
      "0 / 5 : loss = 1458.8170166015625\n",
      "Mean loss in this epoch is: 1342.444580078125\n",
      "==================================================\n",
      "====================Epoch  174 ====================\n",
      "0 / 5 : loss = 1539.7105712890625\n",
      "Mean loss in this epoch is: 1343.342041015625\n",
      "==================================================\n",
      "====================Epoch  175 ====================\n",
      "0 / 5 : loss = 1558.915771484375\n",
      "Mean loss in this epoch is: 1360.5684814453125\n",
      "==================================================\n",
      "====================Epoch  176 ====================\n",
      "0 / 5 : loss = 1524.6441650390625\n",
      "Mean loss in this epoch is: 1352.485107421875\n",
      "==================================================\n",
      "====================Epoch  177 ====================\n",
      "0 / 5 : loss = 1524.82568359375\n",
      "Mean loss in this epoch is: 1343.33935546875\n",
      "==================================================\n",
      "====================Epoch  178 ====================\n",
      "0 / 5 : loss = 1514.692626953125\n",
      "Mean loss in this epoch is: 1347.279541015625\n",
      "==================================================\n",
      "====================Epoch  179 ====================\n",
      "0 / 5 : loss = 1480.627197265625\n",
      "Mean loss in this epoch is: 1361.2152099609375\n",
      "==================================================\n",
      "====================Epoch  180 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1465.5867919921875\n",
      "Mean loss in this epoch is: 1359.7308349609375\n",
      "==================================================\n",
      "====================Epoch  181 ====================\n",
      "0 / 5 : loss = 1490.728271484375\n",
      "Mean loss in this epoch is: 1350.4151611328125\n",
      "==================================================\n",
      "====================Epoch  182 ====================\n",
      "0 / 5 : loss = 1505.2955322265625\n",
      "Mean loss in this epoch is: 1357.2154541015625\n",
      "==================================================\n",
      "====================Epoch  183 ====================\n",
      "0 / 5 : loss = 1524.7891845703125\n",
      "Mean loss in this epoch is: 1353.333251953125\n",
      "==================================================\n",
      "====================Epoch  184 ====================\n",
      "0 / 5 : loss = 1487.46826171875\n",
      "Mean loss in this epoch is: 1356.030517578125\n",
      "==================================================\n",
      "====================Epoch  185 ====================\n",
      "0 / 5 : loss = 1440.9407958984375\n",
      "Mean loss in this epoch is: 1339.4144287109375\n",
      "==================================================\n",
      "====================Epoch  186 ====================\n",
      "0 / 5 : loss = 1503.0137939453125\n",
      "Mean loss in this epoch is: 1351.4554443359375\n",
      "==================================================\n",
      "====================Epoch  187 ====================\n",
      "0 / 5 : loss = 1468.9102783203125\n",
      "Mean loss in this epoch is: 1338.079833984375\n",
      "==================================================\n",
      "====================Epoch  188 ====================\n",
      "0 / 5 : loss = 1493.03076171875\n",
      "Mean loss in this epoch is: 1349.735595703125\n",
      "==================================================\n",
      "====================Epoch  189 ====================\n",
      "0 / 5 : loss = 1461.09326171875\n",
      "Mean loss in this epoch is: 1338.4727783203125\n",
      "==================================================\n",
      "====================Epoch  190 ====================\n",
      "0 / 5 : loss = 1524.318115234375\n",
      "Mean loss in this epoch is: 1360.4327392578125\n",
      "==================================================\n",
      "====================Epoch  191 ====================\n",
      "0 / 5 : loss = 1481.1163330078125\n",
      "Mean loss in this epoch is: 1355.0494384765625\n",
      "==================================================\n",
      "====================Epoch  192 ====================\n",
      "0 / 5 : loss = 1469.7322998046875\n",
      "Mean loss in this epoch is: 1342.0445556640625\n",
      "==================================================\n",
      "====================Epoch  193 ====================\n",
      "0 / 5 : loss = 1487.125244140625\n",
      "Mean loss in this epoch is: 1336.0499267578125\n",
      "==================================================\n",
      "====================Epoch  194 ====================\n",
      "0 / 5 : loss = 1549.0050048828125\n",
      "Mean loss in this epoch is: 1348.44091796875\n",
      "==================================================\n",
      "====================Epoch  195 ====================\n",
      "0 / 5 : loss = 1505.2178955078125\n",
      "Mean loss in this epoch is: 1351.63525390625\n",
      "==================================================\n",
      "====================Epoch  196 ====================\n",
      "0 / 5 : loss = 1509.51953125\n",
      "Mean loss in this epoch is: 1345.561279296875\n",
      "==================================================\n",
      "====================Epoch  197 ====================\n",
      "0 / 5 : loss = 1478.3887939453125\n",
      "Mean loss in this epoch is: 1342.418212890625\n",
      "==================================================\n",
      "====================Epoch  198 ====================\n",
      "0 / 5 : loss = 1530.08740234375\n",
      "Mean loss in this epoch is: 1351.621337890625\n",
      "==================================================\n",
      "====================Epoch  199 ====================\n",
      "0 / 5 : loss = 1454.80810546875\n",
      "Mean loss in this epoch is: 1350.6627197265625\n",
      "==================================================\n",
      "====================Epoch  200 ====================\n",
      "0 / 5 : loss = 1467.8028564453125\n",
      "Mean loss in this epoch is: 1338.8212890625\n",
      "==================================================\n",
      "====================Epoch  201 ====================\n",
      "0 / 5 : loss = 1502.1019287109375\n",
      "Mean loss in this epoch is: 1357.9853515625\n",
      "==================================================\n",
      "====================Epoch  202 ====================\n",
      "0 / 5 : loss = 1507.3729248046875\n",
      "Mean loss in this epoch is: 1338.7237548828125\n",
      "==================================================\n",
      "====================Epoch  203 ====================\n",
      "0 / 5 : loss = 1479.2398681640625\n",
      "Mean loss in this epoch is: 1348.6746826171875\n",
      "==================================================\n",
      "====================Epoch  204 ====================\n",
      "0 / 5 : loss = 1470.692138671875\n",
      "Mean loss in this epoch is: 1344.948486328125\n",
      "==================================================\n",
      "====================Epoch  205 ====================\n",
      "0 / 5 : loss = 1486.59814453125\n",
      "Mean loss in this epoch is: 1326.14111328125\n",
      "==================================================\n",
      "====================Epoch  206 ====================\n",
      "0 / 5 : loss = 1503.8787841796875\n",
      "Mean loss in this epoch is: 1350.0234375\n",
      "==================================================\n",
      "====================Epoch  207 ====================\n",
      "0 / 5 : loss = 1482.1715087890625\n",
      "Mean loss in this epoch is: 1340.49462890625\n",
      "==================================================\n",
      "====================Epoch  208 ====================\n",
      "0 / 5 : loss = 1487.0013427734375\n",
      "Mean loss in this epoch is: 1339.326171875\n",
      "==================================================\n",
      "====================Epoch  209 ====================\n",
      "0 / 5 : loss = 1495.4432373046875\n",
      "Mean loss in this epoch is: 1348.74951171875\n",
      "==================================================\n",
      "====================Epoch  210 ====================\n",
      "0 / 5 : loss = 1536.6417236328125\n",
      "Mean loss in this epoch is: 1340.81591796875\n",
      "==================================================\n",
      "====================Epoch  211 ====================\n",
      "0 / 5 : loss = 1478.8662109375\n",
      "Mean loss in this epoch is: 1337.0284423828125\n",
      "==================================================\n",
      "====================Epoch  212 ====================\n",
      "0 / 5 : loss = 1522.9376220703125\n",
      "Mean loss in this epoch is: 1343.8448486328125\n",
      "==================================================\n",
      "====================Epoch  213 ====================\n",
      "0 / 5 : loss = 1489.0140380859375\n",
      "Mean loss in this epoch is: 1342.688232421875\n",
      "==================================================\n",
      "====================Epoch  214 ====================\n",
      "0 / 5 : loss = 1467.2960205078125\n",
      "Mean loss in this epoch is: 1345.038818359375\n",
      "==================================================\n",
      "====================Epoch  215 ====================\n",
      "0 / 5 : loss = 1461.0380859375\n",
      "Mean loss in this epoch is: 1337.5069580078125\n",
      "==================================================\n",
      "====================Epoch  216 ====================\n",
      "0 / 5 : loss = 1513.010009765625\n",
      "Mean loss in this epoch is: 1345.4161376953125\n",
      "==================================================\n",
      "====================Epoch  217 ====================\n",
      "0 / 5 : loss = 1455.6910400390625\n",
      "Mean loss in this epoch is: 1334.461669921875\n",
      "==================================================\n",
      "====================Epoch  218 ====================\n",
      "0 / 5 : loss = 1488.449951171875\n",
      "Mean loss in this epoch is: 1335.1646728515625\n",
      "==================================================\n",
      "====================Epoch  219 ====================\n",
      "0 / 5 : loss = 1476.3369140625\n",
      "Mean loss in this epoch is: 1332.5706787109375\n",
      "==================================================\n",
      "====================Epoch  220 ====================\n",
      "0 / 5 : loss = 1506.140380859375\n",
      "Mean loss in this epoch is: 1338.5986328125\n",
      "==================================================\n",
      "====================Epoch  221 ====================\n",
      "0 / 5 : loss = 1555.6951904296875\n",
      "Mean loss in this epoch is: 1314.559326171875\n",
      "==================================================\n",
      "====================Epoch  222 ====================\n",
      "0 / 5 : loss = 1465.0372314453125\n",
      "Mean loss in this epoch is: 1327.016845703125\n",
      "==================================================\n",
      "====================Epoch  223 ====================\n",
      "0 / 5 : loss = 1443.7691650390625\n",
      "Mean loss in this epoch is: 1325.124755859375\n",
      "==================================================\n",
      "====================Epoch  224 ====================\n",
      "0 / 5 : loss = 1513.1639404296875\n",
      "Mean loss in this epoch is: 1350.0206298828125\n",
      "==================================================\n",
      "====================Epoch  225 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1443.6761474609375\n",
      "Mean loss in this epoch is: 1338.530029296875\n",
      "==================================================\n",
      "====================Epoch  226 ====================\n",
      "0 / 5 : loss = 1477.8001708984375\n",
      "Mean loss in this epoch is: 1326.64794921875\n",
      "==================================================\n",
      "====================Epoch  227 ====================\n",
      "0 / 5 : loss = 1455.3878173828125\n",
      "Mean loss in this epoch is: 1326.83837890625\n",
      "==================================================\n",
      "====================Epoch  228 ====================\n",
      "0 / 5 : loss = 1477.836669921875\n",
      "Mean loss in this epoch is: 1329.8348388671875\n",
      "==================================================\n",
      "====================Epoch  229 ====================\n",
      "0 / 5 : loss = 1486.1351318359375\n",
      "Mean loss in this epoch is: 1330.068603515625\n",
      "==================================================\n",
      "====================Epoch  230 ====================\n",
      "0 / 5 : loss = 1472.8948974609375\n",
      "Mean loss in this epoch is: 1335.0330810546875\n",
      "==================================================\n",
      "====================Epoch  231 ====================\n",
      "0 / 5 : loss = 1521.6593017578125\n",
      "Mean loss in this epoch is: 1328.614501953125\n",
      "==================================================\n",
      "====================Epoch  232 ====================\n",
      "0 / 5 : loss = 1461.6849365234375\n",
      "Mean loss in this epoch is: 1325.810791015625\n",
      "==================================================\n",
      "====================Epoch  233 ====================\n",
      "0 / 5 : loss = 1522.6885986328125\n",
      "Mean loss in this epoch is: 1333.724365234375\n",
      "==================================================\n",
      "====================Epoch  234 ====================\n",
      "0 / 5 : loss = 1464.5228271484375\n",
      "Mean loss in this epoch is: 1337.292236328125\n",
      "==================================================\n",
      "====================Epoch  235 ====================\n",
      "0 / 5 : loss = 1474.263427734375\n",
      "Mean loss in this epoch is: 1318.345947265625\n",
      "==================================================\n",
      "====================Epoch  236 ====================\n",
      "0 / 5 : loss = 1509.6717529296875\n",
      "Mean loss in this epoch is: 1326.704833984375\n",
      "==================================================\n",
      "====================Epoch  237 ====================\n",
      "0 / 5 : loss = 1444.395263671875\n",
      "Mean loss in this epoch is: 1328.611572265625\n",
      "==================================================\n",
      "====================Epoch  238 ====================\n",
      "0 / 5 : loss = 1452.0540771484375\n",
      "Mean loss in this epoch is: 1315.0279541015625\n",
      "==================================================\n",
      "====================Epoch  239 ====================\n",
      "0 / 5 : loss = 1486.7034912109375\n",
      "Mean loss in this epoch is: 1322.487548828125\n",
      "==================================================\n",
      "====================Epoch  240 ====================\n",
      "0 / 5 : loss = 1433.5098876953125\n",
      "Mean loss in this epoch is: 1312.2406005859375\n",
      "==================================================\n",
      "====================Epoch  241 ====================\n",
      "0 / 5 : loss = 1478.646240234375\n",
      "Mean loss in this epoch is: 1330.9278564453125\n",
      "==================================================\n",
      "====================Epoch  242 ====================\n",
      "0 / 5 : loss = 1405.430908203125\n",
      "Mean loss in this epoch is: 1315.63525390625\n",
      "==================================================\n",
      "====================Epoch  243 ====================\n",
      "0 / 5 : loss = 1498.029541015625\n",
      "Mean loss in this epoch is: 1326.15625\n",
      "==================================================\n",
      "====================Epoch  244 ====================\n",
      "0 / 5 : loss = 1507.5472412109375\n",
      "Mean loss in this epoch is: 1321.67333984375\n",
      "==================================================\n",
      "====================Epoch  245 ====================\n",
      "0 / 5 : loss = 1473.35693359375\n",
      "Mean loss in this epoch is: 1327.4505615234375\n",
      "==================================================\n",
      "====================Epoch  246 ====================\n",
      "0 / 5 : loss = 1473.6397705078125\n",
      "Mean loss in this epoch is: 1325.37060546875\n",
      "==================================================\n",
      "====================Epoch  247 ====================\n",
      "0 / 5 : loss = 1469.289306640625\n",
      "Mean loss in this epoch is: 1329.49462890625\n",
      "==================================================\n",
      "====================Epoch  248 ====================\n",
      "0 / 5 : loss = 1430.6209716796875\n",
      "Mean loss in this epoch is: 1324.348388671875\n",
      "==================================================\n",
      "====================Epoch  249 ====================\n",
      "0 / 5 : loss = 1452.738037109375\n",
      "Mean loss in this epoch is: 1322.88720703125\n",
      "==================================================\n",
      "====================Epoch  250 ====================\n",
      "0 / 5 : loss = 1444.28271484375\n",
      "Mean loss in this epoch is: 1327.4193115234375\n",
      "==================================================\n",
      "====================Epoch  251 ====================\n",
      "0 / 5 : loss = 1442.5494384765625\n",
      "Mean loss in this epoch is: 1320.907470703125\n",
      "==================================================\n",
      "====================Epoch  252 ====================\n",
      "0 / 5 : loss = 1441.688232421875\n",
      "Mean loss in this epoch is: 1322.472900390625\n",
      "==================================================\n",
      "====================Epoch  253 ====================\n",
      "0 / 5 : loss = 1440.192138671875\n",
      "Mean loss in this epoch is: 1322.940673828125\n",
      "==================================================\n",
      "====================Epoch  254 ====================\n",
      "0 / 5 : loss = 1438.805419921875\n",
      "Mean loss in this epoch is: 1311.025390625\n",
      "==================================================\n",
      "====================Epoch  255 ====================\n",
      "0 / 5 : loss = 1472.904541015625\n",
      "Mean loss in this epoch is: 1331.7030029296875\n",
      "==================================================\n",
      "====================Epoch  256 ====================\n",
      "0 / 5 : loss = 1432.4862060546875\n",
      "Mean loss in this epoch is: 1323.5604248046875\n",
      "==================================================\n",
      "====================Epoch  257 ====================\n",
      "0 / 5 : loss = 1448.5780029296875\n",
      "Mean loss in this epoch is: 1317.085205078125\n",
      "==================================================\n",
      "====================Epoch  258 ====================\n",
      "0 / 5 : loss = 1420.3052978515625\n",
      "Mean loss in this epoch is: 1321.9593505859375\n",
      "==================================================\n",
      "====================Epoch  259 ====================\n",
      "0 / 5 : loss = 1456.601806640625\n",
      "Mean loss in this epoch is: 1312.0614013671875\n",
      "==================================================\n",
      "====================Epoch  260 ====================\n",
      "0 / 5 : loss = 1479.3515625\n",
      "Mean loss in this epoch is: 1314.7772216796875\n",
      "==================================================\n",
      "====================Epoch  261 ====================\n",
      "0 / 5 : loss = 1437.9053955078125\n",
      "Mean loss in this epoch is: 1317.9774169921875\n",
      "==================================================\n",
      "====================Epoch  262 ====================\n",
      "0 / 5 : loss = 1445.9002685546875\n",
      "Mean loss in this epoch is: 1310.763916015625\n",
      "==================================================\n",
      "====================Epoch  263 ====================\n",
      "0 / 5 : loss = 1481.058837890625\n",
      "Mean loss in this epoch is: 1318.451171875\n",
      "==================================================\n",
      "====================Epoch  264 ====================\n",
      "0 / 5 : loss = 1466.3656005859375\n",
      "Mean loss in this epoch is: 1324.748291015625\n",
      "==================================================\n",
      "====================Epoch  265 ====================\n",
      "0 / 5 : loss = 1432.609375\n",
      "Mean loss in this epoch is: 1304.945068359375\n",
      "==================================================\n",
      "====================Epoch  266 ====================\n",
      "0 / 5 : loss = 1484.555908203125\n",
      "Mean loss in this epoch is: 1314.505859375\n",
      "==================================================\n",
      "====================Epoch  267 ====================\n",
      "0 / 5 : loss = 1485.32763671875\n",
      "Mean loss in this epoch is: 1331.089111328125\n",
      "==================================================\n",
      "====================Epoch  268 ====================\n",
      "0 / 5 : loss = 1461.2769775390625\n",
      "Mean loss in this epoch is: 1314.6649169921875\n",
      "==================================================\n",
      "====================Epoch  269 ====================\n",
      "0 / 5 : loss = 1460.6309814453125\n",
      "Mean loss in this epoch is: 1324.0782470703125\n",
      "==================================================\n",
      "====================Epoch  270 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1488.23046875\n",
      "Mean loss in this epoch is: 1318.2999267578125\n",
      "==================================================\n",
      "====================Epoch  271 ====================\n",
      "0 / 5 : loss = 1474.2391357421875\n",
      "Mean loss in this epoch is: 1324.36181640625\n",
      "==================================================\n",
      "====================Epoch  272 ====================\n",
      "0 / 5 : loss = 1466.4281005859375\n",
      "Mean loss in this epoch is: 1323.634765625\n",
      "==================================================\n",
      "====================Epoch  273 ====================\n",
      "0 / 5 : loss = 1461.951416015625\n",
      "Mean loss in this epoch is: 1307.6968994140625\n",
      "==================================================\n",
      "====================Epoch  274 ====================\n",
      "0 / 5 : loss = 1490.8204345703125\n",
      "Mean loss in this epoch is: 1325.796875\n",
      "==================================================\n",
      "====================Epoch  275 ====================\n",
      "0 / 5 : loss = 1483.50634765625\n",
      "Mean loss in this epoch is: 1316.4146728515625\n",
      "==================================================\n",
      "====================Epoch  276 ====================\n",
      "0 / 5 : loss = 1464.1181640625\n",
      "Mean loss in this epoch is: 1306.65185546875\n",
      "==================================================\n",
      "====================Epoch  277 ====================\n",
      "0 / 5 : loss = 1449.809326171875\n",
      "Mean loss in this epoch is: 1313.6639404296875\n",
      "==================================================\n",
      "====================Epoch  278 ====================\n",
      "0 / 5 : loss = 1464.59765625\n",
      "Mean loss in this epoch is: 1315.752685546875\n",
      "==================================================\n",
      "====================Epoch  279 ====================\n",
      "0 / 5 : loss = 1453.5946044921875\n",
      "Mean loss in this epoch is: 1311.992919921875\n",
      "==================================================\n",
      "====================Epoch  280 ====================\n",
      "0 / 5 : loss = 1430.03515625\n",
      "Mean loss in this epoch is: 1301.9583740234375\n",
      "==================================================\n",
      "====================Epoch  281 ====================\n",
      "0 / 5 : loss = 1457.745361328125\n",
      "Mean loss in this epoch is: 1309.6790771484375\n",
      "==================================================\n",
      "====================Epoch  282 ====================\n",
      "0 / 5 : loss = 1458.9063720703125\n",
      "Mean loss in this epoch is: 1313.508056640625\n",
      "==================================================\n",
      "====================Epoch  283 ====================\n",
      "0 / 5 : loss = 1453.7105712890625\n",
      "Mean loss in this epoch is: 1304.6318359375\n",
      "==================================================\n",
      "====================Epoch  284 ====================\n",
      "0 / 5 : loss = 1450.1915283203125\n",
      "Mean loss in this epoch is: 1306.711669921875\n",
      "==================================================\n",
      "====================Epoch  285 ====================\n",
      "0 / 5 : loss = 1470.1046142578125\n",
      "Mean loss in this epoch is: 1311.1636962890625\n",
      "==================================================\n",
      "====================Epoch  286 ====================\n",
      "0 / 5 : loss = 1427.281494140625\n",
      "Mean loss in this epoch is: 1304.748291015625\n",
      "==================================================\n",
      "====================Epoch  287 ====================\n",
      "0 / 5 : loss = 1474.2640380859375\n",
      "Mean loss in this epoch is: 1311.7889404296875\n",
      "==================================================\n",
      "====================Epoch  288 ====================\n",
      "0 / 5 : loss = 1438.4493408203125\n",
      "Mean loss in this epoch is: 1299.2265625\n",
      "==================================================\n",
      "====================Epoch  289 ====================\n",
      "0 / 5 : loss = 1452.8692626953125\n",
      "Mean loss in this epoch is: 1309.634521484375\n",
      "==================================================\n",
      "====================Epoch  290 ====================\n",
      "0 / 5 : loss = 1462.6014404296875\n",
      "Mean loss in this epoch is: 1302.512939453125\n",
      "==================================================\n",
      "====================Epoch  291 ====================\n",
      "0 / 5 : loss = 1439.0513916015625\n",
      "Mean loss in this epoch is: 1305.765869140625\n",
      "==================================================\n",
      "====================Epoch  292 ====================\n",
      "0 / 5 : loss = 1499.65087890625\n",
      "Mean loss in this epoch is: 1301.3900146484375\n",
      "==================================================\n",
      "====================Epoch  293 ====================\n",
      "0 / 5 : loss = 1438.796142578125\n",
      "Mean loss in this epoch is: 1307.4871826171875\n",
      "==================================================\n",
      "====================Epoch  294 ====================\n",
      "0 / 5 : loss = 1469.2891845703125\n",
      "Mean loss in this epoch is: 1322.555419921875\n",
      "==================================================\n",
      "====================Epoch  295 ====================\n",
      "0 / 5 : loss = 1437.11572265625\n",
      "Mean loss in this epoch is: 1305.013916015625\n",
      "==================================================\n",
      "====================Epoch  296 ====================\n",
      "0 / 5 : loss = 1459.3553466796875\n",
      "Mean loss in this epoch is: 1317.6370849609375\n",
      "==================================================\n",
      "====================Epoch  297 ====================\n",
      "0 / 5 : loss = 1462.529541015625\n",
      "Mean loss in this epoch is: 1308.6466064453125\n",
      "==================================================\n",
      "====================Epoch  298 ====================\n",
      "0 / 5 : loss = 1456.8917236328125\n",
      "Mean loss in this epoch is: 1305.3011474609375\n",
      "==================================================\n",
      "====================Epoch  299 ====================\n",
      "0 / 5 : loss = 1426.113525390625\n",
      "Mean loss in this epoch is: 1310.165771484375\n",
      "==================================================\n",
      "====================Epoch  300 ====================\n",
      "0 / 5 : loss = 1425.1427001953125\n",
      "Mean loss in this epoch is: 1308.872802734375\n",
      "==================================================\n",
      "====================Epoch  301 ====================\n",
      "0 / 5 : loss = 1428.6151123046875\n",
      "Mean loss in this epoch is: 1296.0062255859375\n",
      "==================================================\n",
      "====================Epoch  302 ====================\n",
      "0 / 5 : loss = 1429.2899169921875\n",
      "Mean loss in this epoch is: 1304.854736328125\n",
      "==================================================\n",
      "====================Epoch  303 ====================\n",
      "0 / 5 : loss = 1466.2568359375\n",
      "Mean loss in this epoch is: 1305.816162109375\n",
      "==================================================\n",
      "====================Epoch  304 ====================\n",
      "0 / 5 : loss = 1474.7340087890625\n",
      "Mean loss in this epoch is: 1302.36767578125\n",
      "==================================================\n",
      "====================Epoch  305 ====================\n",
      "0 / 5 : loss = 1471.5338134765625\n",
      "Mean loss in this epoch is: 1305.820068359375\n",
      "==================================================\n",
      "====================Epoch  306 ====================\n",
      "0 / 5 : loss = 1465.2642822265625\n",
      "Mean loss in this epoch is: 1304.575439453125\n",
      "==================================================\n",
      "====================Epoch  307 ====================\n",
      "0 / 5 : loss = 1435.0155029296875\n",
      "Mean loss in this epoch is: 1293.1312255859375\n",
      "==================================================\n",
      "====================Epoch  308 ====================\n",
      "0 / 5 : loss = 1440.8055419921875\n",
      "Mean loss in this epoch is: 1303.7083740234375\n",
      "==================================================\n",
      "====================Epoch  309 ====================\n",
      "0 / 5 : loss = 1449.2396240234375\n",
      "Mean loss in this epoch is: 1314.444580078125\n",
      "==================================================\n",
      "====================Epoch  310 ====================\n",
      "0 / 5 : loss = 1443.8067626953125\n",
      "Mean loss in this epoch is: 1311.837158203125\n",
      "==================================================\n",
      "====================Epoch  311 ====================\n",
      "0 / 5 : loss = 1456.3828125\n",
      "Mean loss in this epoch is: 1299.507568359375\n",
      "==================================================\n",
      "====================Epoch  312 ====================\n",
      "0 / 5 : loss = 1438.0595703125\n",
      "Mean loss in this epoch is: 1281.797119140625\n",
      "==================================================\n",
      "====================Epoch  313 ====================\n",
      "0 / 5 : loss = 1492.5963134765625\n",
      "Mean loss in this epoch is: 1324.3509521484375\n",
      "==================================================\n",
      "====================Epoch  314 ====================\n",
      "0 / 5 : loss = 1450.0921630859375\n",
      "Mean loss in this epoch is: 1301.413818359375\n",
      "==================================================\n",
      "====================Epoch  315 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1437.71923828125\n",
      "Mean loss in this epoch is: 1290.967529296875\n",
      "==================================================\n",
      "====================Epoch  316 ====================\n",
      "0 / 5 : loss = 1478.2545166015625\n",
      "Mean loss in this epoch is: 1291.7413330078125\n",
      "==================================================\n",
      "====================Epoch  317 ====================\n",
      "0 / 5 : loss = 1477.8212890625\n",
      "Mean loss in this epoch is: 1303.7684326171875\n",
      "==================================================\n",
      "====================Epoch  318 ====================\n",
      "0 / 5 : loss = 1408.5753173828125\n",
      "Mean loss in this epoch is: 1280.647705078125\n",
      "==================================================\n",
      "====================Epoch  319 ====================\n",
      "0 / 5 : loss = 1429.56201171875\n",
      "Mean loss in this epoch is: 1298.340576171875\n",
      "==================================================\n",
      "====================Epoch  320 ====================\n",
      "0 / 5 : loss = 1435.5208740234375\n",
      "Mean loss in this epoch is: 1309.9296875\n",
      "==================================================\n",
      "====================Epoch  321 ====================\n",
      "0 / 5 : loss = 1471.24169921875\n",
      "Mean loss in this epoch is: 1303.1810302734375\n",
      "==================================================\n",
      "====================Epoch  322 ====================\n",
      "0 / 5 : loss = 1413.00244140625\n",
      "Mean loss in this epoch is: 1285.5694580078125\n",
      "==================================================\n",
      "====================Epoch  323 ====================\n",
      "0 / 5 : loss = 1450.82958984375\n",
      "Mean loss in this epoch is: 1296.863037109375\n",
      "==================================================\n",
      "====================Epoch  324 ====================\n",
      "0 / 5 : loss = 1470.46826171875\n",
      "Mean loss in this epoch is: 1298.2835693359375\n",
      "==================================================\n",
      "====================Epoch  325 ====================\n",
      "0 / 5 : loss = 1479.2835693359375\n",
      "Mean loss in this epoch is: 1302.73828125\n",
      "==================================================\n",
      "====================Epoch  326 ====================\n",
      "0 / 5 : loss = 1397.109375\n",
      "Mean loss in this epoch is: 1285.4365234375\n",
      "==================================================\n",
      "====================Epoch  327 ====================\n",
      "0 / 5 : loss = 1423.979248046875\n",
      "Mean loss in this epoch is: 1295.358642578125\n",
      "==================================================\n",
      "====================Epoch  328 ====================\n",
      "0 / 5 : loss = 1486.368896484375\n",
      "Mean loss in this epoch is: 1303.451171875\n",
      "==================================================\n",
      "====================Epoch  329 ====================\n",
      "0 / 5 : loss = 1479.5303955078125\n",
      "Mean loss in this epoch is: 1298.9576416015625\n",
      "==================================================\n",
      "====================Epoch  330 ====================\n",
      "0 / 5 : loss = 1392.770263671875\n",
      "Mean loss in this epoch is: 1274.3194580078125\n",
      "==================================================\n",
      "====================Epoch  331 ====================\n",
      "0 / 5 : loss = 1416.0849609375\n",
      "Mean loss in this epoch is: 1291.527099609375\n",
      "==================================================\n",
      "====================Epoch  332 ====================\n",
      "0 / 5 : loss = 1418.332275390625\n",
      "Mean loss in this epoch is: 1283.741455078125\n",
      "==================================================\n",
      "====================Epoch  333 ====================\n",
      "0 / 5 : loss = 1447.5980224609375\n",
      "Mean loss in this epoch is: 1297.61474609375\n",
      "==================================================\n",
      "====================Epoch  334 ====================\n",
      "0 / 5 : loss = 1441.365478515625\n",
      "Mean loss in this epoch is: 1290.1759033203125\n",
      "==================================================\n",
      "====================Epoch  335 ====================\n",
      "0 / 5 : loss = 1449.84375\n",
      "Mean loss in this epoch is: 1297.6849365234375\n",
      "==================================================\n",
      "====================Epoch  336 ====================\n",
      "0 / 5 : loss = 1417.253173828125\n",
      "Mean loss in this epoch is: 1283.213134765625\n",
      "==================================================\n",
      "====================Epoch  337 ====================\n",
      "0 / 5 : loss = 1433.4510498046875\n",
      "Mean loss in this epoch is: 1298.671142578125\n",
      "==================================================\n",
      "====================Epoch  338 ====================\n",
      "0 / 5 : loss = 1400.5263671875\n",
      "Mean loss in this epoch is: 1287.052734375\n",
      "==================================================\n",
      "====================Epoch  339 ====================\n",
      "0 / 5 : loss = 1436.3272705078125\n",
      "Mean loss in this epoch is: 1294.1263427734375\n",
      "==================================================\n",
      "====================Epoch  340 ====================\n",
      "0 / 5 : loss = 1433.4393310546875\n",
      "Mean loss in this epoch is: 1296.916015625\n",
      "==================================================\n",
      "====================Epoch  341 ====================\n",
      "0 / 5 : loss = 1462.581298828125\n",
      "Mean loss in this epoch is: 1296.861328125\n",
      "==================================================\n",
      "====================Epoch  342 ====================\n",
      "0 / 5 : loss = 1419.236572265625\n",
      "Mean loss in this epoch is: 1295.096435546875\n",
      "==================================================\n",
      "====================Epoch  343 ====================\n",
      "0 / 5 : loss = 1449.26953125\n",
      "Mean loss in this epoch is: 1290.545654296875\n",
      "==================================================\n",
      "====================Epoch  344 ====================\n",
      "0 / 5 : loss = 1376.7003173828125\n",
      "Mean loss in this epoch is: 1282.78369140625\n",
      "==================================================\n",
      "====================Epoch  345 ====================\n",
      "0 / 5 : loss = 1422.579345703125\n",
      "Mean loss in this epoch is: 1268.28515625\n",
      "==================================================\n",
      "====================Epoch  346 ====================\n",
      "0 / 5 : loss = 1415.8695068359375\n",
      "Mean loss in this epoch is: 1289.0416259765625\n",
      "==================================================\n",
      "====================Epoch  347 ====================\n",
      "0 / 5 : loss = 1430.300537109375\n",
      "Mean loss in this epoch is: 1297.90234375\n",
      "==================================================\n",
      "====================Epoch  348 ====================\n",
      "0 / 5 : loss = 1412.409912109375\n",
      "Mean loss in this epoch is: 1278.93310546875\n",
      "==================================================\n",
      "====================Epoch  349 ====================\n",
      "0 / 5 : loss = 1473.662353515625\n",
      "Mean loss in this epoch is: 1280.5838623046875\n",
      "==================================================\n",
      "====================Epoch  350 ====================\n",
      "0 / 5 : loss = 1428.81640625\n",
      "Mean loss in this epoch is: 1290.0968017578125\n",
      "==================================================\n",
      "====================Epoch  351 ====================\n",
      "0 / 5 : loss = 1415.063232421875\n",
      "Mean loss in this epoch is: 1285.639892578125\n",
      "==================================================\n",
      "====================Epoch  352 ====================\n",
      "0 / 5 : loss = 1479.9169921875\n",
      "Mean loss in this epoch is: 1302.072021484375\n",
      "==================================================\n",
      "====================Epoch  353 ====================\n",
      "0 / 5 : loss = 1409.363525390625\n",
      "Mean loss in this epoch is: 1270.1763916015625\n",
      "==================================================\n",
      "====================Epoch  354 ====================\n",
      "0 / 5 : loss = 1433.656005859375\n",
      "Mean loss in this epoch is: 1281.951416015625\n",
      "==================================================\n",
      "====================Epoch  355 ====================\n",
      "0 / 5 : loss = 1435.131103515625\n",
      "Mean loss in this epoch is: 1285.1082763671875\n",
      "==================================================\n",
      "====================Epoch  356 ====================\n",
      "0 / 5 : loss = 1420.290283203125\n",
      "Mean loss in this epoch is: 1263.842041015625\n",
      "==================================================\n",
      "====================Epoch  357 ====================\n",
      "0 / 5 : loss = 1398.994140625\n",
      "Mean loss in this epoch is: 1274.0474853515625\n",
      "==================================================\n",
      "====================Epoch  358 ====================\n",
      "0 / 5 : loss = 1480.6060791015625\n",
      "Mean loss in this epoch is: 1307.6409912109375\n",
      "==================================================\n",
      "====================Epoch  359 ====================\n",
      "0 / 5 : loss = 1422.7451171875\n",
      "Mean loss in this epoch is: 1275.617431640625\n",
      "==================================================\n",
      "====================Epoch  360 ====================\n",
      "0 / 5 : loss = 1433.9464111328125\n",
      "Mean loss in this epoch is: 1281.894775390625\n",
      "==================================================\n",
      "====================Epoch  361 ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5 : loss = 1421.951416015625\n",
      "Mean loss in this epoch is: 1261.7005615234375\n",
      "==================================================\n",
      "====================Epoch  362 ====================\n",
      "0 / 5 : loss = 1428.150390625\n",
      "Mean loss in this epoch is: 1270.88232421875\n",
      "==================================================\n",
      "====================Epoch  363 ====================\n",
      "0 / 5 : loss = 1400.502685546875\n",
      "Mean loss in this epoch is: 1266.255615234375\n",
      "==================================================\n",
      "====================Epoch  364 ====================\n",
      "0 / 5 : loss = 1427.40673828125\n",
      "Mean loss in this epoch is: 1276.71728515625\n",
      "==================================================\n",
      "====================Epoch  365 ====================\n",
      "0 / 5 : loss = 1388.04541015625\n",
      "Mean loss in this epoch is: 1276.93505859375\n",
      "==================================================\n",
      "====================Epoch  366 ====================\n",
      "0 / 5 : loss = 1457.4873046875\n",
      "Mean loss in this epoch is: 1288.2647705078125\n",
      "==================================================\n",
      "====================Epoch  367 ====================\n",
      "0 / 5 : loss = 1452.24853515625\n",
      "Mean loss in this epoch is: 1275.646728515625\n",
      "==================================================\n",
      "====================Epoch  368 ====================\n",
      "0 / 5 : loss = 1460.7403564453125\n",
      "Mean loss in this epoch is: 1271.432861328125\n",
      "==================================================\n",
      "====================Epoch  369 ====================\n",
      "0 / 5 : loss = 1427.5560302734375\n",
      "Mean loss in this epoch is: 1257.822998046875\n",
      "==================================================\n",
      "====================Epoch  370 ====================\n",
      "0 / 5 : loss = 1395.814453125\n",
      "Mean loss in this epoch is: 1274.601318359375\n",
      "==================================================\n",
      "====================Epoch  371 ====================\n",
      "0 / 5 : loss = 1434.3779296875\n",
      "Mean loss in this epoch is: 1276.139404296875\n",
      "==================================================\n",
      "====================Epoch  372 ====================\n",
      "0 / 5 : loss = 1385.5433349609375\n",
      "Mean loss in this epoch is: 1267.361572265625\n",
      "==================================================\n",
      "====================Epoch  373 ====================\n",
      "0 / 5 : loss = 1430.806640625\n",
      "Mean loss in this epoch is: 1279.3525390625\n",
      "==================================================\n",
      "====================Epoch  374 ====================\n",
      "0 / 5 : loss = 1418.7393798828125\n",
      "Mean loss in this epoch is: 1287.5260009765625\n",
      "==================================================\n",
      "====================Epoch  375 ====================\n",
      "0 / 5 : loss = 1429.576416015625\n",
      "Mean loss in this epoch is: 1277.15087890625\n",
      "==================================================\n",
      "====================Epoch  376 ====================\n",
      "0 / 5 : loss = 1376.339111328125\n",
      "Mean loss in this epoch is: 1272.8922119140625\n",
      "==================================================\n",
      "====================Epoch  377 ====================\n",
      "0 / 5 : loss = 1406.716796875\n",
      "Mean loss in this epoch is: 1275.793701171875\n",
      "==================================================\n",
      "====================Epoch  378 ====================\n",
      "0 / 5 : loss = 1389.5994873046875\n",
      "Mean loss in this epoch is: 1261.396484375\n",
      "==================================================\n",
      "====================Epoch  379 ====================\n",
      "0 / 5 : loss = 1386.75634765625\n",
      "Mean loss in this epoch is: 1264.7275390625\n",
      "==================================================\n",
      "====================Epoch  380 ====================\n",
      "0 / 5 : loss = 1417.01806640625\n",
      "Mean loss in this epoch is: 1275.188232421875\n",
      "==================================================\n",
      "====================Epoch  381 ====================\n",
      "0 / 5 : loss = 1391.435546875\n",
      "Mean loss in this epoch is: 1261.110595703125\n",
      "==================================================\n",
      "====================Epoch  382 ====================\n",
      "0 / 5 : loss = 1403.4818115234375\n",
      "Mean loss in this epoch is: 1255.49560546875\n",
      "==================================================\n",
      "====================Epoch  383 ====================\n",
      "0 / 5 : loss = 1353.169677734375\n",
      "Mean loss in this epoch is: 1263.391845703125\n",
      "==================================================\n",
      "====================Epoch  384 ====================\n",
      "0 / 5 : loss = 1424.482177734375\n",
      "Mean loss in this epoch is: 1273.2359619140625\n",
      "==================================================\n",
      "====================Epoch  385 ====================\n",
      "0 / 5 : loss = 1414.11474609375\n",
      "Mean loss in this epoch is: 1254.5211181640625\n",
      "==================================================\n",
      "====================Epoch  386 ====================\n",
      "0 / 5 : loss = 1393.9932861328125\n",
      "Mean loss in this epoch is: 1269.570068359375\n",
      "==================================================\n",
      "====================Epoch  387 ====================\n",
      "0 / 5 : loss = 1393.7879638671875\n",
      "Mean loss in this epoch is: 1259.584228515625\n",
      "==================================================\n",
      "====================Epoch  388 ====================\n",
      "0 / 5 : loss = 1379.500244140625\n",
      "Mean loss in this epoch is: 1272.8265380859375\n",
      "==================================================\n",
      "====================Epoch  389 ====================\n",
      "0 / 5 : loss = 1416.168701171875\n",
      "Mean loss in this epoch is: 1267.802001953125\n",
      "==================================================\n",
      "====================Epoch  390 ====================\n",
      "0 / 5 : loss = 1393.286865234375\n",
      "Mean loss in this epoch is: 1270.4857177734375\n",
      "==================================================\n",
      "====================Epoch  391 ====================\n",
      "0 / 5 : loss = 1384.8385009765625\n",
      "Mean loss in this epoch is: 1264.161376953125\n",
      "==================================================\n",
      "====================Epoch  392 ====================\n",
      "0 / 5 : loss = 1410.0732421875\n",
      "Mean loss in this epoch is: 1278.6793212890625\n",
      "==================================================\n",
      "====================Epoch  393 ====================\n",
      "0 / 5 : loss = 1388.9490966796875\n",
      "Mean loss in this epoch is: 1258.660400390625\n",
      "==================================================\n",
      "====================Epoch  394 ====================\n",
      "0 / 5 : loss = 1411.180419921875\n",
      "Mean loss in this epoch is: 1263.341064453125\n",
      "==================================================\n",
      "====================Epoch  395 ====================\n",
      "0 / 5 : loss = 1396.688232421875\n",
      "Mean loss in this epoch is: 1263.6846923828125\n",
      "==================================================\n",
      "====================Epoch  396 ====================\n",
      "0 / 5 : loss = 1416.4244384765625\n",
      "Mean loss in this epoch is: 1261.842529296875\n",
      "==================================================\n",
      "====================Epoch  397 ====================\n",
      "0 / 5 : loss = 1373.4327392578125\n",
      "Mean loss in this epoch is: 1268.5499267578125\n",
      "==================================================\n",
      "====================Epoch  398 ====================\n",
      "0 / 5 : loss = 1392.4195556640625\n",
      "Mean loss in this epoch is: 1261.6290283203125\n",
      "==================================================\n",
      "====================Epoch  399 ====================\n",
      "0 / 5 : loss = 1427.0850830078125\n",
      "Mean loss in this epoch is: 1268.4188232421875\n",
      "==================================================\n",
      "(214132, 16)\n"
     ]
    }
   ],
   "source": [
    "Testinglist = []             \n",
    "\n",
    "classifier = Model(args,Testinglist)\n",
    "s_ItemUser, s_UserF, s_UserEmbedding  = classifier.run()\n",
    "np.savetxt('s_LMI.txt',s_ItemUser)\n",
    "np.savetxt('s_MDA.txt',s_UserF)\n",
    "np.savetxt('s_MicroRNA_Embedding.txt',s_UserEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def covert_file_to_matrix(file_dir):\n",
    "    # convert the file to matrix\n",
    "    return_matrix = []\n",
    "    # open the known miRNA similarity file\n",
    "    # there is 271 similarity score from a paper by Wang et. al\n",
    "    # the other 224 similarity scores are calculated by Gaussian interaction profile kernel similarity\n",
    "    with open(file_dir) as temp_opener:\n",
    "        temp_lines = temp_opener.readlines()\n",
    "        for line in temp_lines:\n",
    "            line_str_list = line.split(' ')\n",
    "            line_float_list = list(map(float, line_str_list))\n",
    "            # if there is an association, assign 1 to the matrix\n",
    "            return_matrix.append(line_float_list)\n",
    "\n",
    "    return np.array(return_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_ma = covert_file_to_matrix('../results/MVMTMDA/s_MDA.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 268)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmi_matrix = np.zeros(result_ma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmda_dir = '../data/MVMTMDA/miRNA-disease_id.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open the known miRNA-disease association file\n",
    "# the first column represents miRNA\n",
    "# the total number is N=495\n",
    "# the second column represents disease\n",
    "# the total number is M=383\n",
    "with open(kmda_dir) as temp_opener:\n",
    "    temp_lines = temp_opener.readlines()\n",
    "    for line in temp_lines:\n",
    "        line_str_list = line.split('::')\n",
    "        line_int_list = list(map(int, line_str_list))\n",
    "        miRNA_code = line_int_list[1]\n",
    "        disease_code = line_int_list[0]\n",
    "        # if there is an association, assign 1 to the matrix\n",
    "        if miRNA_code-1 < result_ma.shape[0]:\n",
    "            dmi_matrix[miRNA_code - 1][disease_code - 1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 268)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmi_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_precision_score(ori_matrix, pre_matrix):\n",
    "        \n",
    "    # For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(dmi_matrix.shape[1]):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(ori_matrix[:, i],pre_matrix[:, i])\n",
    "        average_precision[i] = average_precision_score(ori_matrix[:, i], pre_matrix[:, i])\n",
    "    \n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(ori_matrix.ravel(),pre_matrix.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(ori_matrix, pre_matrix, average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.step(recall['micro'], precision['micro'], where='post')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score, micro-averaged over all classes: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_precision_score(dmi_matrix, result_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_curve(ori_matrix, pre_matrix):\n",
    "        \n",
    "    # For each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(dmi_matrix.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(ori_matrix[:, i], pre_matrix[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ori_matrix.ravel(), pre_matrix.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    print('ROC AUC: {0:0.2f}'.format(roc_auc[\"micro\"]))\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.39\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_roc_curve(dmi_matrix, result_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ma = covert_file_to_matrix('../results/MVMTMDA/4000_MDA.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score, micro-averaged over all classes: 0.07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_precision_score(dmi_matrix, result_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:813: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.49\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_roc_curve(dmi_matrix, result_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
